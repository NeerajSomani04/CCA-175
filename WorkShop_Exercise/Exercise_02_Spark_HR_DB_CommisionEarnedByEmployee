Description

There is database by name hr in lab, host - ms.itversity.com, user name hr_user, password itversity. 
Use best programming practices, than trying to do every thing using scala 
(for eg, if you write sql try to get as much work as possible done in sql it self)

Problem Statement::
Let us get commission earned by each and every employee
For each and every employee who have commission_pct set compute commission earned in dollars (by multiplying salary with commission_pct)
Print employee name, salary and commission earned
If commission_pct is null in database, print “N/E” for commission earned

Solution:
-- using spark RDD --
--- Need to launch the spark-shell with installing avro package
spark-shell --master yarn --packages com.databricks:spark-avro_2.10:2.0.1 --conf spark.ui.port=12567
--- Need to launch the spark-shell with installing csv package
spark-shell --master yarn --packages com.databricks:spark-csv_2.11:1.3.0 --conf spark.ui.port=12567

-- this file is tab seperated. came to know after reading and analyzing it.

val employees = sc.textFile("/public/hr_db/employees")
val employeesWithCommission = employees.filter(employee => employee.split("\t")(8) != "null").map( employee => (employee.split("\t")(1)+" "+employee.split("\t")(2), employee.split("\t")(7).toFloat, (employee.split("\t")(7).toFloat * employee.split("\t")(8).toFloat).toString))
val employeesWithOutCommission = employees.filter(employee => employee.split("\t")(8) == "null").map( employee => (employee.split("\t")(1)+" "+employee.split("\t")(2), employee.split("\t")(7).toFloat, "N/E"))
val employeesResult = employeesWithCommission.union(employeesWithOutCommission)

val employeeDF = employeesResult.toDF("employee_name", "salary", "commission_earned")

-- To save data frame in json format, use below command:-
employeeDF.write.json("/user/dkothari/WS_Exercise_02/json/")

-- To save data frame in avro format, we can use either of the below command:-
import com.databricks.spark.avro._;
employeeDF.write.avro("/user/dkothari/WS_Exercise_02/avro/")
------- or -----
employeeDF.save("/user/dkothari/WS_Exercise_02/avro123/", "com.databricks.spark.avro")

-- To save data frame in csv format, we can use below command:-
import com.databricks.spark.csv._;
employeeDF.write.format("com.databricks.spark.csv").option("header", "true").save("/user/dkothari/WS_Exercise_02/csv/")
employeeDF.save("/user/dkothari/WS_Exercise_02/csv1/", "com.databricks.spark.csv")

--- To save data frame in csv format, with compression codec ---
employeeDF.write.format("com.databricks.spark.csv").option("header", "true")
.option("codec", "org.apache.hadoop.io.compress.GzipCodec")
.save("/user/dkothari/WS_Exercise_02/csv12/")

--- To save dataframe in csv format, with (\t) tab seperated
employeeDF.write.format("com.databricks.spark.csv").option("header", "true")
.option("delimiter", "\t").save("/user/dkothari/WS_Exercise_02/csv12/")


-- using spark SQL --

val employeesJsonDF = sqlContext.read.json("/user/dkothari/WS_Exercise_02/json/")
employeesJsonDF.registerTempTable("employeesTable")
val finalDF = sqlContext.sql("select * from employeesTable")
finalDF.write.avro("/user/dkothari/WS_Exercise_02/avro/")

--- we can use sql comething like below --
select first_name, salary,
(case when (ifnull(commission_pct,0) = 0.00 )
THEN 'N/A’
ELSE (salary *commission_pct)
END) CommisionEarned
from employeesTable
--------------------------


