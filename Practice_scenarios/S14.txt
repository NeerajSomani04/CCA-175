14. Problem Scenario 14 : You have been given following mysql database details as well as other info. 

User=retail_dba 
password=cloudera 
database=retail_db 
jdbc URL = jdbc:mysql://quickstart:3306/retail_db 
Please accomplish following activities. 
1. Create a csv file named updated_departments.csv with the following contents in local file system. 
2,fitness 
3,footwear 
12,fathematics 
13,fcience 
14,engineering 
1000,management 

[dkothari@gw03 ~]$ vi updated_departments.csv
2. copy to hdfs path
[dkothari@gw03 ~]$ hadoop fs -copyFromLocal updated_departments.csv /user/dkothari/updated_departments

3. Now export this data from hdfs to mysql retail_export.dkothari_departments_export table. During upload make sure existing 
department will just updated and new departments needs to be inserted.
Solution:
sqoop export \
--connect jdbc:mysql://ms.itversity.com:3306/retail_export \
--username retail_user \
--password itversity \
--table dkothari_departments_export \
--columns "department_id, department_name" \
--export-dir /user/dkothari/updated_departments \
--update-key "department_id" \
--update-mode updateonly


Note: for some reason --update-mode 'allowinsert' is not working in above sqoop statment. but 'updateonly' is working as expected. 

we can also try some aurguments like below in same sqoop statement:
--input-fields-terminated-by ','




