1.
sqoop import \
--connect \
--username \
--password \
--table orders \
--target-dir /user/cloudera/Arun_problems/problem1/orders \
--as-avrodatafile \
--compress \
--compression-codec=snappy 

2.
sqoop import \
--connect \
--username \
--password \
--table orders \
--target-dir /user/cloudera/Arun_problems/problem1/order_items \
--as-avrodatafile \
--compress \
--compression-codec=snappy 

3.
import com.databricks.spark.avro._;

val ordersDF = sqlContext.read.avro("/user/cloudera/Arun_problems/problem1/orders")
val orderItemsDF = sqlContext.read.avro("/user/cloudera/Arun_problems/problem1/order_items")

val DataFrameResult = ordersDF.join(orderItemsDF, ordersDF("order_id") === orderItemsDF("order_item_order_id"))
.groupBy(to_date(from_unixtime(col("order_date")/1000)).alias("order_date"), col("order_status"))
.agg(countDistinct("order_id").alias("total_orders"), round(sum("order_item_subtotal"),2).alias("total_amount"))
.orderBy(col("order_date").desc, col("order_status"), col("total_amount").desc, col("total_orders"))

4.
sqlContext.setConf("org.apache.hadoop.io.compress.codec","GzipCodec")
DataFrameResult.write.option("compression","gzip").parquet("/user/cloudera/Arun_problems/problem1/result4a-gzip_3rd")
