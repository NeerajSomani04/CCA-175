1.
sqoop import \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--target-dir /user/cloudera/Arun_problems/problem4/text \
--fields-terminated-by "\t" \
--lines-terminated-by "\n"

2. 
sqoop import \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--target-dir /user/cloudera/Arun_problems/problem4/avro \
--as-avrodatafile

3. 
sqoop import \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--target-dir /user/cloudera/Arun_problems/problem4/parquet \
--as-parquetfile

4. 
4a.
import com.databricks.spark.avro._;
sqlContext.setConf("spark.sql.parquet.compression.codec","snappy")
val orderDF = sqlContext.read.avro("/user/cloudera/Arun_problems/problem4/avro")
orderDF.write.parquet("/user/cloudera/Arun_problems/problem4/parquet-snappy-compress")

4b.
orderDF.map(x => x(0)+"\t"+x(1)+"\t"+x(2)+"\t"+x(3)).saveAsTextFile("/user/cloudera/Arun_problems/problem4/text-gzip-compress", classOf[org.apache.hadoop.io.compress.GzipCodec])

4c.
orderDF.map(x => x(0)+"\t"+x(1)+"\t"+x(2)+"\t"+x(3)).saveAsSequenceFile("/user/cloudera/Arun_problems/problem4/sequence")

4d.
orderDF.map(x => x(0)+"\t"+x(1)+"\t"+x(2)+"\t"+x(3)).saveAsTextFile("/user/cloudera/Arun_problems/problem4/text-snappy-compress", classOf[org.apache.hadoop.io.compress.SnappyCodec])

5.
5a.
val parSnappyDF = sqlContext.read.parquet("/user/cloudera/Arun_problems/problem4/parquet-snappy-compress")
sqlContext.setConf("spark.sql.parquet.compression.codec","uncompressed")
parSnappyDF.write.parquet("/user/cloudera/Arun_problems/problem4/parquet-no-compress")

5b.
sqlContext.setConf("spark.sql.avro.compression.codec","snappy")
parSnappyDF.write.avro("/user/cloudera/Arun_problems/problem4/avro-snappy")

6.
6a.
val avroSnappyDF = sqlContext.read.avro("/user/cloudera/Arun_problems/problem4/avro-snappy")
avroSnappyDF.toJSON.saveAsTextFile("/user/cloudera/Arun_problems/problem4/json-no-compress")

6b.
avroSnappyDF.toJSON.saveAsTextFile("/user/cloudera/Arun_problems/problem4/json-gzip", classOf[org.apache.hadoop.io.compress.GzipCodec])

7.
val jsonDF = sqlContext.read.json("/user/cloudera/Arun_problems/problem4/json-gzip")
jsonDF.map( x => x(0) + "," + x(1) +"," + x(2) + "," + x(3)).saveAsTextFile("/user/cloudera/Arun_problems/problem4/csv-gzip")

8. 
jsonDF.write.orc("/user/cloudera/Arun_problems/problem4/orc")
