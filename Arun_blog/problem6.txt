
1. in hive window
create database arunproblem6;

2.
sqoop import-all-tables \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--hive-import \
--hive-database arunproblem6 

3.
var hc = new org.apache.spark.sql.hive.HiveContext(sc);

hc.sql("")

dataframe example for rank and dense rank
https://stackoverflow.com/questions/42966590/scala-spark-how-do-we-rank-dataframe-with-sqlcontext-and-version-1-5/42972123

https://stackoverflow.com/questions/44968912/difference-in-dense-rank-and-row-number-in-spark

--------- using Spark DataFrame ---------------
1.
sqoop import-all-tables \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--warehouse-dir /user/cloudera/Arun_problems/problem6 \

2. 
We can't read data directly from hive. hence, imported data to hdfs location and then read data from there.

3.
val departmentRDD = sc.textFile("/user/cloudera/Arun_problems/problem6/departments")
val categoriesRDD = sc.textFile("/user/cloudera/Arun_problems/problem6/categories")
val productsRDD = sc.textFile("/user/cloudera/Arun_problems/problem6/products")

case class Departments(departmentId: Int, departmentName: String)
case class Categories(category_id: Int, category_department_id: Int, category_name: String)
case class Products(product_id: Int, product_category_id: Int, product_name: String, product_description: String, product_price: Float, product_image: String)

-----------------------------
I used below 2 commands to identify one row that has "," (comma) in data column "product_description")

scala> productsRDD.filter( x => x.split(",")(4) == "").first
res54: String = 685,31,TaylorMade SLDR Irons - (Steel) 4-PW, AW,,899.99,http://images.acmesports.sports/TaylorMade+SLDR+Irons+-+%28Steel%29+4-PW%2C+AW                                                              

scala> productsRDD.filter( x => x.split(",")(3) != "").first
res56: String = 685,31,TaylorMade SLDR Irons - (Steel) 4-PW, AW,,899.99,http://images.acmesports.sports/TaylorMade+SLDR+Irons+-+%28Steel%29+4-PW%2C+AW
------------------------------

val departDF = departmentRDD.map(x => x.split(",")).map( x => Departments(x(0).toInt, x(1).toString)).toDF()
val catDF = categoriesRDD.map( x => x.split(",")).map( x => Categories(x(0).toInt, x(1).toInt, x(2).toString)).toDF()

val prodDF = productsRDD.map{ x => if (x.split(",")(4) == "") x.replace(" AW,", "") else x }.map( x => x.split(",")).map( x => Products(x(0).toInt, x(1).toInt, x(2).toString, x(3).toString, x(4).toFloat, x(5).toString)).toDF()

----------------------------------------------------------------
How to show full column content in a Spark Dataframe?
prodDF.show(20, false)
or //
prodDF.show(false)
------------------------------------------------------------------

import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.functions._

val windowSpec = Window.partitionBy(col("departmentId")).orderBy(col("product_price"))

val DataFrameResult = departDF.join(catDF, departDF("departmentId") === catDF("category_department_id")).join(prodDF, catDF("category_id") === prodDF("product_category_id")).withColumn("rank", rank().over(windowSpec)).withColumn("dense_rank", dense_rank().over(windowSpec)).select(departDF("departmentId"), prodDF("product_id"), prodDF("product_name"), prodDF("product_price"), $"rank", $"dense_rank").orderBy(col("departmentId"), col("rank").desc)

4.
val customerRDD = sc.textFile("/user/cloudera/Arun_problems/problem6/customers")
val ordersRDD = sc.textFile("/user/cloudera/Arun_problems/problem6/orders")
val orderItemsRDD = sc.textFile("/user/cloudera/Arun_problems/problem6/order_items")

-- I have created case classes based on below link ---
http://www.itversity.com/topic/companion-objects-case-classes/

val ordersDF=ordersRDD.map(rec => rec.split(",")).map( b => Order(b(0).toInt,b(1),b(2).toInt,b(3)) ).toDF()
val orderItemsDF=orderItemsRDD.map(rec => rec.split(",")).map( b => OrderItem(b(0).toInt,b(1).toInt,b(2).toInt,b(3).toInt,b(4).toFloat,b(5).toFloat ) ).toDF()
val customersDF = customerRDD.map(rec => rec.split(",")).map( b => Customer(b(0).toInt,b(1),b(2),b(3),b(4),b(5),b(6),b(7),b(8)) ).toDF()

val DataFrameResult = ordersDF.join(orderItemsDF, ordersDF("orderId") === orderItemsDF("orderItemOrderId")).join(customersDF, ordersDF("orderCustomerId") === customersDF("customerId")).groupBy(customersDF("customerId"),customersDF("customerFname")).agg(countDistinct(orderItemsDF("orderItemProductId"))).orderBy(customersDF("customerId")).take(10)


5.
val DataFrameResult = departDF.join(catDF, departDF("departmentId") === catDF("category_department_id")).join(prodDF, catDF("category_id") === prodDF("product_category_id")).withColumn("rank", rank().over(windowSpec)).withColumn("dense_rank", dense_rank().over(windowSpec)).filter(prodDF("product_price") < 100).select(departDF("departmentId"), prodDF("product_id"), prodDF("product_name"), prodDF("product_price"), $"rank", $"dense_rank").orderBy(col("departmentId"), col("rank").desc)


