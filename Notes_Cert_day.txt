Below are the points one should remember Exam Day:

a) Need to check first about python version and make proper environment settings to update and use python 3.x version. 

b) you need to make sure about ip addresses and port number for differenet services running on CDH multinode cluster. 
      In exam cluster mysql and hdfs could be at different node. means different servers (ip-addresses).
      
c) Open 4 applications on CDH:
    1) Sublim / any other text editor
    2) Cloudera Manager
    3) Terminal 
        a) for Hive
        b) for pyspark --> 2 terminal to work on 2 problems simultaneously. This is because code usually takes long time to run.
        c) for mysql
        d) sqoop
        e) need to update from here if needed for flume/impala/
        
d) There should be some UI in cloudera that provides information about Namenode. NameNode will give us information about many important components. Need to locate and understand core-site.xml, hdfs-site.xml, yarn-site.xml, spark-env.sh

e) understand memory and cluster capacity will help to leverage cluster properly and run jobs in proper manner. This way we can execute jobs fast and save some time in exam.

f) At time of certification, cloudera wouldn't allow us to connect to mysql. we need to validate any mysql queries through sqoop.

g) to get details about cluster, which is in Yarn mode.
      cat /etc/hadoop/conf/yarn-site.xml
      linux command --> once you open the file type "/yarn.resourcemanager" and hit enter. this command will serach matching pattern in file.
      yarn.resourcemanager.webapp.address --> this is the property name that will give us information about yarn resource manager address.

h) Durga sir mentioned that their will be different datasets and not only one like retail_db. Although, questions will be much simpler than what we are practicing in video series. 3 to 8 lines of code in 10 min for 1 question is the expectation. but don't completely rely on this statement.

i) dont use tabs for typing in spark or sublime text for exam. Spark treats tab differently and can create some issues in exam. Instead use space twice, which is equal to one tab. (one tab == two space bars)

j) some important questions:
      1) How to sort String data into Ascending and Descending order
      2) How to read multiple data files from local file system into spark and create RDD from it.
      3) 

k) List details of all configuartion files related to each technology. This will help us find any configuartion related details at the time of certification:

1) Hadoop conf file --> cat /etc/hadoop/conf/core-site.xml
2) yarn conf file --> cat /opt/yarn/conf/yarn-site.xml
3) spark conf file -->
4) mysql db conf related details --> like jdbc url connection url, etc..
5) Hive warehouse details on cluster -->
6) 
