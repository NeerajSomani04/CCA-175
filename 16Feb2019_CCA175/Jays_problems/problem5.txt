sqoop import \
--connect jdbc:mysql://localhost/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--as-avrodatafile \
--compression-codec "snappy" \
--target-dir /user/cloudera/jays_problems/problem5-avro-snappy


sqoop import \
--connect jdbc:mysql://localhost/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--as-parquetfile \
--compression-codec "snappy" \
--target-dir /user/cloudera/jays_problems/problem5-parquet-snappy


val DF1 = sqlContext.read.avro("/user/cloudera/jays_problems/problem5-avro-snappy")

val DF2 = DF1.filter($"order_status" === "COMPLETE").filter($"order_id" > 1000 and $"order_id" < 50000)

val DF3 = DF2.select("order_id","order_status")

sqlContext.setConf("spark.sql.parquet.compression.codec","Gzip")
DF3.repartition(2).write.parquet("/user/cloudera/jays_problems/problem5-parquet-gzip")
