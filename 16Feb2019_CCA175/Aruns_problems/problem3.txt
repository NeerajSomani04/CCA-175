problem3 -->

1. 
sqoop import-all-tables \
--connect jdbc:mysql://ms.itversity.com:3306/retail_db \
--username retail_user \
--password itversity \
--num-mappers 4 \
--autoreset-to-one-mapper \
--as-avrodatafile \
--compress \
--compression-codec 'org.apache.hadoop.io.compress.SnappyCodec' \
--warehouse-dir /user/hive/warehouse/dkothari_arunproblem3_retail_stage.db 

2.
create database dkothari_arunproblem3_retail_stage;
use dkothari_arunproblem3_retail_stage;

create external table orders_sqoop(order_id int, order_date timestamp, order_customer_id int, order_status string) stored as avro location '/user/hive/warehouse/dkothari_arunproblem3_retail_stage.db/orders' tblproperties('avro.schema.url'='/user/dkothari/16Feb2019_CCA/arun_problems/attempt1/problem3/orders.avsc');

3. 
select * from orders_sqoop as X where X.order_date in (select temp1.order_date from (select Y.order_date, count(1) as order_count from orders_sqoop Y group by Y.order_date order by order_count desc limit 1) as temp1);

4. same SQL as above

5. 
create external table orders_avro(order_id int, order_date date, order_customer_id int, order_status string) partitioned by (order_month string) stored as avro;

Insert overwrite table orders_avro partition (order_month) select order_id, to_date(from_unixtime(cast(order_date/1000 as int))) as order_date, order_customer_id, order_status, substr(to_date(from_unixtime(cast(order_date/1000 as int))), 1, 7) as order_month from orders_sqoop;

select order_id, to_date(from_unixtime(cast(order_date/1000 as int))), order_customer_id, order_status, substr(from_unixtime(cast(order_date/1000 as int)),1,7) as order_month from default.orders_sqoop;

select cast(order_date/1000 as int) from orders_sqoop limit 5;


select order_id, cast(from_unixtime(order_date/1000) as date) as order_date, order_customer_id, order_status, substr(cast(from_unixtime(order_date/1000) as date), 1, 7) as order_month from orders_sqoop;
