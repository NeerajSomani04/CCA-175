Exercise 5 --> 

/*
spark-shell --master yarn \
  --conf spark.ui.port=12456 \
  --num-executors 10 \
  --executor-memory 3G \
  --executor-cores 2 \
  --packages com.databricks:spark-avro_2.10:2.0.1
*/

val wordRDD = sc.textFile("/public/randomtextwriter")

val finalDF = wordRDD.flatMap(x => x.split(" ")).map(x => (x,1)).reduceByKey((x,y) => x+y).toDF("word","count")

import com.databricks.spark.avro._

finalDF.write.avro("/user/dkothari/16Feb2019_CCA/sparkExercise/solution05/wordcount")
